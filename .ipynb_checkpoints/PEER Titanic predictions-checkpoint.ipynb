{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic predictions using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import VotingClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10,7]\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "data = train_df.append(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed, there are many missing values in Age and Cabin which will need to be filled\n",
    "\n",
    "First, let's try to see how the given features are related to Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.heatmap(train_df.drop('PassengerId',axis=1).corr(), annot=True, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon initial inspection, Age, SibSp and Parch have very weak relationships with Survived as compared to Pclass and Age\n",
    "\n",
    "However, there are transitive relationships such as Age, Pclass and Survived; these will need to be further inspected\n",
    "\n",
    "The missing values will also affect correlation, which might change once those values are filled appropriately\n",
    "\n",
    "The features Sex, Cabin, Ticket, Embarked need to be converted to integral values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore Pclass vs Survived\n",
    "g = sns.catplot(data=train_df, y='Survived', x='Pclass', kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the economy class of passengers affects their survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore Age vs Survived\n",
    "g = sns.catplot(data=train_df, x='Survived', y='Age', kind='bar', height=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore SibSp vs Survived\n",
    "g = sns.catplot(data=train_df, x='SibSp', y='Survived', kind='bar', height=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore Parch vs Survived\n",
    "g = sns.catplot(data=train_df, x='Parch', y='Survived', kind='bar', height=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The increased survival of passengers travelling with siblings/parents/children hints at the requirement of features \n",
    "that indicate whether a passenger was travelling with family or not.\n",
    "\n",
    "Families had a higher survival rate than individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore Fare vs Survived\n",
    "g = sns.catplot(data=train_df, y='Fare', x='Survived', kind='bar', height=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously observed, the (pseudo) economic status affected survival \n",
    "\n",
    "The remaining features can also help in aiding and generating features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Names to create a Title column\n",
    "\n",
    "There are various titles across all passengers; let's simplify that into 'Dr', 'Master', 'Miss', 'Mr', 'Mrs', 'Rev'(Reverend) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Title'] = data['Name']\n",
    "for name_string in data['Name']:\n",
    "    data['Title'] = data['Name'].str.extract('([A-Za-z]+)\\.', expand=True)\n",
    "data['Title'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the missing age values by the medians of titles for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_changes = {'Mlle': 'Miss', 'Major': 'Mr', 'Col': 'Mr', 'Sir': 'Mr', 'Don': 'Mr', 'Mme': 'Miss',\n",
    "          'Jonkheer': 'Mr', 'Lady': 'Mrs', 'Capt': 'Mr', 'Countess': 'Mrs', 'Ms': 'Miss', 'Dona': 'Mrs'}\n",
    "data.replace({'Title': title_changes}, inplace=True)\n",
    "titles = ['Dr', 'Master', 'Miss', 'Mr', 'Mrs', 'Rev']\n",
    "for title in titles:\n",
    "    age_to_impute = data.groupby('Title')['Age'].median()[titles.index(title)]\n",
    "    data.loc[(data['Age'].isnull()) & (data['Title'] == title), 'Age'] = age_to_impute\n",
    "train_df['Age'] = data['Age'][:891]\n",
    "test_df['Age'] = data['Age'][891:]\n",
    "data.drop('Title', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a new feature that helps identify whether a passenger was alone or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Family_Size'] = data['Parch'] + data['SibSp'] + 1\n",
    "train_df['Family_Size'] = data['Family_Size'][:891]\n",
    "test_df['Family_Size'] = data['Family_Size'][891:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to identify the family/group that each passenger belonged to, there are two approaches:\n",
    "\n",
    "1. Check for common last name and fare\n",
    "2. Check for same ticket initials\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Last_Name'] = data['Name'].apply(lambda x: str.split(x, \",\")[0])\n",
    "data['Fare'].fillna(data['Fare'].mean(), inplace=True)\n",
    "DEFAULT_SURVIVAL_VALUE = 0.5\n",
    "data['Family_Survival'] = DEFAULT_SURVIVAL_VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for grp, grp_df in data[['Survived','Name', 'Last_Name', 'Fare', 'Ticket', 'PassengerId',\n",
    "                           'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['Last_Name', 'Fare']):   \n",
    "    if (len(grp_df) != 1):\n",
    "        for ind, row in grp_df.iterrows():\n",
    "            smax = grp_df.drop(ind)['Survived'].max()\n",
    "            smin = grp_df.drop(ind)['Survived'].min()\n",
    "            passID = row['PassengerId']\n",
    "            if (smax == 1.0):\n",
    "                data.loc[data['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "            elif (smin==0.0):\n",
    "                data.loc[data['PassengerId'] == passID, 'Family_Survival'] = 0\n",
    "print(\"Number of passengers with family survival information:\", \n",
    "      data.loc[data['Family_Survival']!=0.5].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, grp_df in data.groupby('Ticket'):\n",
    "    if (len(grp_df) != 1):\n",
    "        for ind, row in grp_df.iterrows():\n",
    "            if (row['Family_Survival'] == 0) | (row['Family_Survival']== 0.5):\n",
    "                smax = grp_df.drop(ind)['Survived'].max()\n",
    "                smin = grp_df.drop(ind)['Survived'].min()\n",
    "                passID = row['PassengerId']\n",
    "                if (smax == 1.0):\n",
    "                    data.loc[data['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "                elif (smin==0.0):\n",
    "                    data.loc[data['PassengerId'] == passID, 'Family_Survival'] = 0                      \n",
    "print(\"Number of passenger with family/group survival information: \" \n",
    "      +str(data[data['Family_Survival']!=0.5].shape[0]))\n",
    "train_df['Family_Survival'] = data['Family_Survival'][:891]\n",
    "test_df['Family_Survival'] = data['Family_Survival'][891:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organise Fare and Age into bins alongwith encoding for various features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Fare'].fillna(data['Fare'].median(), inplace = True)\n",
    "data['FareBin'] = pd.qcut(data['Fare'], 5)\n",
    "label = LabelEncoder()\n",
    "data['FareBin_Code'] = label.fit_transform(data['FareBin'])\n",
    "train_df['FareBin_Code'] = data['FareBin_Code'][:891]\n",
    "test_df['FareBin_Code'] = data['FareBin_Code'][891:]\n",
    "train_df.drop(['Fare'], 1, inplace=True)\n",
    "test_df.drop(['Fare'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['AgeBin'] = pd.qcut(data['Age'], 4)\n",
    "label = LabelEncoder()\n",
    "data['AgeBin_Code'] = label.fit_transform(data['AgeBin'])\n",
    "train_df['AgeBin_Code'] = data['AgeBin_Code'][:891]\n",
    "test_df['AgeBin_Code'] = data['AgeBin_Code'][891:]\n",
    "train_df.drop(['Age'], 1, inplace=True)\n",
    "test_df.drop(['Age'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Sex'].replace(['male','female'],[0,1],inplace=True)\n",
    "test_df['Sex'].replace(['male','female'],[0,1],inplace=True)\n",
    "train_df.drop(['Name', 'PassengerId', 'SibSp', 'Parch', 'Ticket', 'Cabin',\n",
    "               'Embarked'], axis = 1, inplace = True)\n",
    "test_df.drop(['Name','PassengerId', 'SibSp', 'Parch', 'Ticket', 'Cabin',\n",
    "              'Embarked'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_df.drop('Survived', axis=1)\n",
    "y = train_df['Survived']\n",
    "\n",
    "x_test = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "#Stratified k fold cross validation\n",
    "kfold = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "x = std_scaler.fit_transform(x)\n",
    "x_test = std_scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store scores of all models\n",
    "gs_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaboost\n",
    "DTC = DecisionTreeClassifier()\n",
    "\n",
    "adaDTC = AdaBoostClassifier(DTC, random_state=7)\n",
    "\n",
    "ada_param_grid = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n",
    "              \"base_estimator__splitter\" :   [\"best\", \"random\"],\n",
    "              \"algorithm\" : [\"SAMME\",\"SAMME.R\"],\n",
    "              \"n_estimators\" :[1,2],\n",
    "              \"learning_rate\":  [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5]}\n",
    "\n",
    "gsadaDTC = GridSearchCV(adaDTC,param_grid = ada_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= -1, verbose = 1)\n",
    "\n",
    "gsadaDTC.fit(x,y)\n",
    "\n",
    "ada_best = gsadaDTC.best_estimator_\n",
    "\n",
    "#Best score \n",
    "gs_scores['Ada'] = gsadaDTC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ExtraTrees \n",
    "ExtC = ExtraTreesClassifier()\n",
    "\n",
    "\n",
    "## Search grid for optimal parameters\n",
    "ex_param_grid = {\"max_depth\": [None],\n",
    "              \"max_features\": [None, 'auto'],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [False],\n",
    "              \"n_estimators\" :[100,300],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "\n",
    "\n",
    "gsExtC = GridSearchCV(ExtC,param_grid = ex_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= -1, verbose = 1)\n",
    "\n",
    "gsExtC.fit(x,y)\n",
    "\n",
    "ExtC_best = gsExtC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gs_scores['ET'] = gsExtC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFC Parameters tunning \n",
    "RFC = RandomForestClassifier()\n",
    "\n",
    "\n",
    "## Search grid for optimal parameters\n",
    "rf_param_grid = {\"max_depth\": [None],\n",
    "              \"max_features\": [None, 'auto'],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [False],\n",
    "              \"n_estimators\" :[100,300],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "\n",
    "\n",
    "gsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= -1, verbose = 1)\n",
    "\n",
    "gsRFC.fit(x,y)\n",
    "\n",
    "RFC_best = gsRFC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gs_scores['RFC'] = gsRFC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosting tunning\n",
    "\n",
    "GBC = GradientBoostingClassifier()\n",
    "gb_param_grid = {'loss' : [\"deviance\"],\n",
    "              'n_estimators' : [100,200,300],\n",
    "              'learning_rate': [0.1, 0.05, 0.01],\n",
    "              'max_depth': [4, 8],\n",
    "              'min_samples_leaf': [100,150],\n",
    "              'max_features': [None, 'auto'] \n",
    "              }\n",
    "\n",
    "gsGBC = GridSearchCV(GBC,param_grid = gb_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= -1, verbose = 1)\n",
    "\n",
    "gsGBC.fit(x,y)\n",
    "\n",
    "GBC_best = gsGBC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gs_scores['GBC'] = gsGBC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "\n",
    "SVMC = SVC(probability=True)\n",
    "svc_param_grid = {'kernel':['rbf'],\n",
    "                  'gamma':[0.001,0.01,0.1,1],\n",
    "                  'C':[0.1,1,10,50,100,200,300,]}\n",
    "gsSVMC = GridSearchCV(SVMC, param_grid=svc_param_grid, cv=kfold, scoring='accuracy', n_jobs = -1, verbose = 1)\n",
    "\n",
    "gsSVMC.fit(x,y)\n",
    "\n",
    "SVMC_best = gsSVMC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gs_scores['SVC'] = gsSVMC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "n_neighbors = [6,7,8,9,10,11,12,14,16,18,20,22]\n",
    "algorithm = ['auto']\n",
    "weights = ['uniform', 'distance']\n",
    "leaf_size = list(range(1,50,5))\n",
    "hyperparams = {'algorithm': algorithm,\n",
    "               'weights': weights,\n",
    "               'leaf_size': leaf_size,\n",
    "               'n_neighbors': n_neighbors}\n",
    "\n",
    "gsKNN=GridSearchCV(estimator = knn, param_grid = hyperparams, verbose=1, cv=10, scoring = \"roc_auc\", n_jobs=-1)\n",
    "\n",
    "gsKNN.fit(x, y)\n",
    "\n",
    "knn_best = gsKNN.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gs_scores['KNN'] = gsKNN.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_scores_df = pd.DataFrame(gs_scores, index=[0])\n",
    "gs_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(data=gs_scores_df,kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_reduced_features(models):\n",
    "#     model_num=1\n",
    "#     for model in models:\n",
    "#         print('Model', model_num)\n",
    "#         rfecv = RFECV(estimator=model, step=1, cv=kfold, scoring='accuracy')\n",
    "#         rfecv.fit(x,y)\n",
    "#         print('Optimal no. of features: ', rfecv.n_features_)\n",
    "#         feat_support = rfecv.support_\n",
    "#         feat_grid_score = rfecv.grid_scores_\n",
    "#         print('Selected columns are: ', *x.columns[feat_support])\n",
    "#         print('Not selected columns are: ', *x.columns[feat_support!=True])\n",
    "#         print('Cross val score: ', feat_grid_score.mean(), end='\\n\\n')\n",
    "#         model_num+=1\n",
    "    \n",
    "\n",
    "# get_reduced_features([RFC_best,ExtC_best,ada_best,GBC_best])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# votingC = VotingClassifier(estimators=[('rfc', RFC_best), ('extc', ExtC_best),\n",
    "# ('svc', SVMC_best), ('adac',ada_best),('gbc',GBC_best), ('knn',knn_best)], voting='soft', n_jobs=-1)\n",
    "\n",
    "# votingC = votingC.fit(x,y)\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# print(cross_val_score(votingC, x, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get predictions for test data\n",
    "# y_pred = votingC.predict(x_test)\n",
    "knn = KNeighborsClassifier(algorithm='auto', leaf_size=26, metric='minkowski', \n",
    "                           metric_params=None, n_jobs=1, n_neighbors=6, p=2, \n",
    "                           weights='uniform')\n",
    "knn.fit(x, y)\n",
    "y_pred = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(pd.read_csv(\"/kaggle/input/titanic/test.csv\")['PassengerId'])\n",
    "temp['Survived'] = y_pred\n",
    "temp.to_csv(\"../working/submission.csv\", index = False)\n",
    "print(\"Predictions submitted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
